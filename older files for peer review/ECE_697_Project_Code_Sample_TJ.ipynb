{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECE 697 Project Code Sample TJ.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMxCIYZRZZpJO3TG1Kq+XL5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Description of code: This sample of code has been used in our project to extract certain features from the information provided in pcap files. The code also batches those features into blocks with a maximum size of 10, based on the IP address. This batching is the first version we used in our project, where the values of the ten rows are summed together.\n",
        "\n",
        "The first portion of the code just involves loading the sample data file, which has been provided in our github folder. The file is titled \"sample pcap data for code peer review.csv\". This file contains 25 rows of data from 3 different IP addresses. The end result of the code should produce data on those 3 batches of IP addresses. \n",
        "\n",
        "I have noted the block of code to start your review. You will need to change the file path in the pd.read.csv to make sure you are mapping it to the location of the sample pcap data file."
      ],
      "metadata": {
        "id": "Zo2eTgTTgMn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mGRam7FwFlk0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b75f4e-433f-4223-c033-791edfb0627a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df_SUEE17_short = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ECE 697/sample pcap data for code peer review.csv')\n",
        "\n",
        "a,b = np.shape(data_df_SUEE17_short) # dimension of dataset to be used later in manual feature extraction\n",
        "info_data = data_df_SUEE17_short['Info'] # loading only the \"Info\" column of Wireshark output file\n",
        "\n",
        "print('number of samples in dataset: ', a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfEMXO6FGnix",
        "outputId": "2a81f4bc-3b4a-495a-c549-7dc3cff8d775"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of samples in dataset:  25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start review here:"
      ],
      "metadata": {
        "id": "iCD6W58-hsqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_features = np.zeros((a,16)) # matrix to house the newly extracted features\n",
        "\n",
        "#define some keywords that we are going to search for\n",
        "PCAP_keywords = ['SYN','FIN','PSH','ACK', 'reassembled PDU', 'unseen segment', 'Previus segment not captured', 'HTTP', 'Fragmented', 'Bad', 'UDP', 'Malformed', 'Null', 'TCP']\n",
        "PCAP_integers = ['Seq', 'Ack']\n",
        "\n",
        "for i in range(0,a): # iterate through all the data samples\n",
        "  keyword_count = 0 # for new_features index\n",
        "  for j in PCAP_keywords: # iterate through all of the keywords we want to search for\n",
        "    found_keyword = info_data[i].find(j)\n",
        "    if found_keyword >= 0:\n",
        "      new_features[i,keyword_count] = 1 # if keyword is found\n",
        "    if found_keyword == -1: \n",
        "      new_features[i,keyword_count] = 0 # if keyword is not found\n",
        "    keyword_count = keyword_count + 1\n",
        "\n",
        "  for k in PCAP_integers: # now going to iterate though all the integers we are looking for\n",
        "    start_location = info_data[i].find(k) \n",
        "    end_location = info_data[i].find(' ',start_location) # if we find the keyword, we want the location of the space afterwards to locate the integer\n",
        "    found_integer = info_data[i][start_location+4:end_location] # then keep just the integer, not the location\n",
        "\n",
        "    if start_location >= 0:\n",
        "      new_features[i,keyword_count] = found_integer # if keyword is found, save integer\n",
        "    if start_location == -1:\n",
        "      new_features[i,keyword_count] = 0 # if keyword is not found, save a zero\n",
        "\n",
        "    keyword_count = keyword_count + 1"
      ],
      "metadata": {
        "id": "vMuza5F6J7F0"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a new dataframe with our newly extracted features, then concatenate it with our original sample dataframe:\n",
        "new_features_df = pd.DataFrame(new_features, columns = ['SYN','FIN','PSH','ACK','PDU','unseen','nocap','HTTPreq','fragmented','bad','UDP','malformed','null','TCP','Seq#','Ack#']) #https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
        "data_df_SUEE17_short_new = pd.concat([data_df_SUEE17_short,new_features_df], axis=1) #https://pandas.pydata.org/docs/reference/api/pandas.concat.html"
      ],
      "metadata": {
        "id": "GppoX8Yol9MF"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#next we will batch these features based on IP address:\n",
        "batching_samples = data_df_SUEE17_short_new.head(a) #https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html\n",
        "batching_samples = batching_samples.to_numpy() #https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_numpy.html\n",
        "np.shape(batching_samples)\n",
        "\n",
        "start_index = 0 #start at the first IP address\n",
        "stop_index = 0\n",
        "new_data = np.zeros((a,17)) # new matrix to contain our newly batched features\n",
        "\n",
        "for j in range (0,a):\n",
        "  ip_start = batching_samples[start_index,2] # locate the IP address for the starting index\n",
        "\n",
        "  #look at the next 10 samples, decide where to stop(either at 10, or when the IP address changes). If we reach the end of all samples, then stop there\n",
        "  if start_index >= a-10:\n",
        "    for i in range (start_index+1,a):\n",
        "      if ip_start != batching_samples[i,2]:\n",
        "        stop_index = i\n",
        "        break\n",
        "      stop_index = i\n",
        "  else:\n",
        "    for i in range (start_index+1,start_index+10):\n",
        "      if ip_start != batching_samples[i,2]:\n",
        "        stop_index = i\n",
        "        break\n",
        "      stop_index = i\n",
        "\n",
        "  #matrix that contains only the rows we care about for this specific batch\n",
        "  batch_matrix = batching_samples[start_index:stop_index,0:23]\n",
        "\n",
        "  #calculate new features\n",
        "  for k in range(0,16):\n",
        "    new_data[j,k] = sum(batch_matrix[:,k+7])\n",
        "  \n",
        "  start_index = stop_index"
      ],
      "metadata": {
        "id": "nlvUtGi4l9Cu"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stop Review Here"
      ],
      "metadata": {
        "id": "nP7ahy8siOKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Note: Here is the output generated. We can see that the first three rows of the new_data table have been populated with sum() values from the batched IP addresses. The 25 samples provided consisted of 9 rows from the first IP address, 6 rows from the second IP address, and 10 rows from the third IP address. This table shows the respective sums from the first 9 rows of the newly generated features, then the next 6 rows, then the next 10 rows.\n"
      ],
      "metadata": {
        "id": "LqZsuAvPiQ5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOW-3sbRdhpb",
        "outputId": "e053a35a-0a55-4ee2-cf79-cad6684b22df"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1.,   0.,   7.,   9.,   6.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   7., 885.,   8.,   0.],\n",
              "       [  1.,   0.,   4.,   6.,   4.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   4., 466.,   5.,   0.],\n",
              "       [  5.,   0.,   1.,   8.,   1.,   0.,   0.,   1.,   0.,   0.,   0.,\n",
              "          0.,   0.,   3.,   3.,   3.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    }
  ]
}
